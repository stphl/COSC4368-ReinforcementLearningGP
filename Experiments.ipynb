{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments base implementation\n",
    "def experiment_1(q_table, alpha, gamma, num_steps):\n",
    "    # Set up agents with Q-learning and specified parameters\n",
    "    redAgent = Agent(0)\n",
    "    blueAgent = Agent(1)\n",
    "    blackAgent = Agent(2)\n",
    "    agents = [redAgent, blueAgent, blackAgent]\n",
    "\n",
    "    # Initial environment state\n",
    "    initialEnvironment = [3, 3, 5, 3, 1, 3, 0, 0, 0, 0, 0, 0, 5, 5, 5]\n",
    "\n",
    "    # Initialize the Q-table\n",
    "    q_table = QTable(6, 6, 6, alpha, gamma)\n",
    "\n",
    "    # Run PRANDOM for 500 steps\n",
    "    for step in range(500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PRANDOM\")\n",
    "\n",
    "    # Run Q-learning for the next 8500 steps with PRANDOM policy\n",
    "    for step in range(8500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PRANDOM\")\n",
    "\n",
    "    # Run PGREEDY for the remaining 8500 steps\n",
    "    for step in range(8500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PGREEDY\")\n",
    "\n",
    "    # Run PEXPLOIT for the remaining 8500 steps\n",
    "    for step in range(8500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PEXPLOIT\")\n",
    "\n",
    "    # Print final Q-table for PEXPLOIT\n",
    "    q_table.print_q_table()\n",
    "\n",
    "def experiment_2(q_table, alpha, gamma, num_steps):\n",
    "    # Set up agents with SARSA and specified parameters\n",
    "    redAgent = Agent(0)\n",
    "    blueAgent = Agent(1)\n",
    "    blackAgent = Agent(2)\n",
    "    agents = [redAgent, blueAgent, blackAgent]\n",
    "\n",
    "    # Initial environment state\n",
    "    initialEnvironment = [3, 3, 5, 3, 1, 3, 0, 0, 0, 0, 0, 0, 5, 5, 5]\n",
    "\n",
    "    # Initialize the Q-table\n",
    "    q_table = QTable(6, 6, 6, alpha, gamma)\n",
    "\n",
    "    # Run PRANDOM for 500 steps\n",
    "    for step in range(500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PRANDOM\")\n",
    "\n",
    "    # Run SARSA for the remaining 8500 steps with PEXPLOIT policy\n",
    "    for step in range(8500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PEXPLOIT\")\n",
    "\n",
    "    # Print final Q-table for SARSA\n",
    "    q_table.print_q_table()\n",
    "\n",
    "def experiment_3(q_table, alpha1, alpha2, gamma, num_steps):\n",
    "    # Set up agents with Q-learning and specified parameters\n",
    "    redAgent = Agent(0)\n",
    "    blueAgent = Agent(1)\n",
    "    blackAgent = Agent(2)\n",
    "    agents = [redAgent, blueAgent, blackAgent]\n",
    "\n",
    "    # Initial environment state\n",
    "    initialEnvironment = [3, 3, 5, 3, 1, 3, 0, 0, 0, 0, 0, 0, 5, 5, 5]\n",
    "\n",
    "    # Initialize the Q-table with different learning rates\n",
    "    q_table1 = QTable(6, 6, 6, alpha1, gamma)\n",
    "    q_table2 = QTable(6, 6, 6, alpha2, gamma)\n",
    "\n",
    "    # Run PRANDOM for 500 steps\n",
    "    for step in range(500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table1, \"PRANDOM\")\n",
    "\n",
    "    # Run PEXPLOIT for the remaining 8500 steps with different learning rates\n",
    "    for step in range(8500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table1, \"PEXPLOIT\")\n",
    "\n",
    "    # Print final Q-table for PEXPLOIT with alpha1\n",
    "    q_table1.print_q_table()\n",
    "\n",
    "    # Run PEXPLOIT for the remaining 8500 steps with different learning rates\n",
    "    for step in range(8500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table2, \"PEXPLOIT\")\n",
    "\n",
    "    # Print final Q-table for PEXPLOIT with alpha2\n",
    "    q_table2.print_q_table()\n",
    "\n",
    "def experiment_4(q_table, alpha, gamma, num_steps):\n",
    "    # Set up agents with Q-learning and specified parameters\n",
    "    redAgent = Agent(0)\n",
    "    blueAgent = Agent(1)\n",
    "    blackAgent = Agent(2)\n",
    "    agents = [redAgent, blueAgent, blackAgent]\n",
    "\n",
    "    # Initial environment state\n",
    "    initialEnvironment = [3, 3, 5, 3, 1, 3, 0, 0, 0, 0, 0, 0, 5, 5, 5]\n",
    "\n",
    "    # Initialize the Q-table\n",
    "    q_table = QTable(6, 6, 6, alpha, gamma)\n",
    "\n",
    "    # Run PRANDOM for the first 500 steps\n",
    "    for step in range(500):\n",
    "        for agent in agents:\n",
    "            agent.step(initialEnvironment, q_table, \"PRANDOM\")\n",
    "\n",
    "    terminal_state_count = 0\n",
    "    pickup_locations_changed = False\n",
    "\n",
    "    # Run PEXPLOIT until the terminal state is reached the sixth time\n",
    "    while terminal_state_count < 6:\n",
    "        for agent in agents:\n",
    "            next_move = \"PEXPLOIT\"\n",
    "            if terminal_state_count >= 3 and not pickup_locations_changed:\n",
    "                # Change pickup locations after reaching terminal state the third time\n",
    "                initialEnvironment[12:15] = [4, 2, 3, 3, 2, 4]\n",
    "                pickup_locations_changed = True\n",
    "            new_game_state = agent.step(initialEnvironment, q_table, next_move)\n",
    "            if new_game_state[6] == 5:  # Check if terminal state is reached\n",
    "                terminal_state_count += 1\n",
    "\n",
    "    # Print final Q-table for PEXPLOIT\n",
    "    q_table.print_q_table()\n",
    "\n",
    "\n",
    "# Run Experiments\n",
    "experiment_1(QTable, 0.3, 0.5, 9000)\n",
    "experiment_2(QTable, 0.3, 0.5, 9000)\n",
    "experiment_3(QTable, 0.15, 0.45, 0.5, 9000)\n",
    "experiment_4(QTable, 0.3, 0.5, 9000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
